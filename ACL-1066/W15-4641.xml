<sec_map><section><chunk>Proceedings of the SIGDIAL 2015 Conference, pages 295304, Prague, Czech Republic, 2-4 September 2015. c 2015 Association for Computational Linguistics Recurrent Polynomial Network for Dialogue State Tracking with Mismatched Semantic Parsers Qizhe Xie, Kai Sun, Su Zhu, Lu Chen and Kai Yu Key Lab. of Shanghai Education Commission for Intelligent Interaction and Cognitive Eng. SpeechLab, Department of Computer Science and Engineering Shanghai Jiao Tong University, Shanghai, China {cheezer,accreator,paul2204,chenlusz,kai.yu}@sjtu.edu.cn Abstract Recently, constrained Markov Bayesian polynomial (CMBP) has been proposed as a data-driven rule-based model for di- alog state tracking (DST). CMBP is an ap- proach to bridge rule-based models and statistical models. Recurrent Polyno- mial Network (RPN) is a recent statisti- cal framework taking advantages of rule- based models and can achieve state-of- the-art performance on the data corpora of DSTC-3, outperforming all submitted trackers in DSTC-3 including RNN. It is widely acknowledged that SLUs re- liability influences trackers performance greatly, especially in cases where the train- ing SLU is poorly matched to the testing SLU. In this paper, this effect is analyzed in detail for RPN. Experiments show that RPNs tracking result is consistently the best compared to rule-based and statistical models investigated on different SLUs in- cluding mismatched ones and demonstrate RPNs is very robust to mismatched se- mantic parsers. </chunk></section><section><heading>1 Introduction </heading><chunk>Dialogue management is the core of a spoken di- alogue system. As a dialogue progresses, dia- logue management usually accomplishes two mis- sions. One mission is called dialogue state track- ing (DST), which is a process to estimate the dis- tribution of the dialogue states. Another mission is to choose semantics-level machine dialogue acts to direct the dialogue given the information of the dialogue state, referred to as dialogue decision making. Due to unpredictable user behaviours, in- evitable automatic speech recognition (ASR) and spoken language understanding (SLU) errors, dia- logue state tracking and decision making are dif- ficult (Williams and Young, 2007). Consequently, much research has been devoted to statistical di- alogue management. In previous studies, dia- logue state tracking and decision making are usu- ally investigated together. In recent years, to ad- vance the research of statistical dialogue manage- ment, the DST problem is raised out of the sta- tistical dialogue management framework so that a bunch of models can be investigated for DST. Moreover, shared research tasks like the Dialog State Tracking Challenge (DSTC) (Williams et al., 2013; Henderson et al., 2014a; Henderson et al., 2014b) have provided a common testbed and eval- uation suite to facilitate direct comparisons among DST models. Two DST model categories are broadly known, i.e, rule-based models and statistical models. Re- cent studies on constrained Markov Bayesian polynomial (CMBP) framework took the first step towards bridging the gap between rule-based and statistical approaches for DST (Sun et al., 2014a; Yu et al., 2015). CMBP formulates rule-based DST in a general way and allows data-driven rules to be generated, so the performance can be im- proved when training data is available. This en- ables CMBP to achieve competitive performance to the state-of-the-art statistical approaches, while at the same time keeping most of the advantages of rule-based models. Nevertheless, adding features to CMBP is not as easy as in most other statis- tical approaches because additional prior knowl- edge is needed to be added to keep the search space tractable (Sun et al., 2014a; Yu et al., 2015). For the same reason, increasing the model com- plexity is difficult. To tackle the weakness of CMBP, recurrent polynomial network (RPN) (Sun et al., 2015) is proposed to further bridge the gap between rule-based and statistical approaches for DST (Sun et al., 2015). RPNs unique structure enables the framework to have all the advantages of CMBP. Additionally, RPN achieves more prop- erties of statistical approaches than CMBP. RPN 295 uses gradient descent where CMBP uses Hill- climbing. Hence RPN can train its parameters faster and the parameter space are not limited to grid where parameters only takes values which are a multiple of a constant. SLU is usually the input module of tracker. Hence its performance affect state trackings per- formance greatly. However, it is hard to design a reliable parser because of ASR errors and the difficulty of obtaining in-domain data. Further, it is a common case that SLU on a trackers train- ing data is very different from SLU on a trackers testing data in real world end-to-end dialogue sys- tem. Thus, RPN is evaluated on SLUs with great variance and especially in the case where SLU for training mismatches SLU for testing. RPN shows consistently best results among trackers investi- gated on all SLUs. The contribution of this paper is to investigate more complex RPN structures with deeper layers, multiple activation nodes and more features and to evaluate RPNs performance in mismatched SLU condition. The rest of the paper is organized as follows. Section 2 introduces rule-based models and sta- tistical models used in DST. Section 3 introduces two frameworks CMBP and RPN bridging rule- based models and statistical models. Complex RPN structures are also introduced in this section. Section 4 discusses the influence of SLU on track- ing and the SLU mismatch condition. Section 5 evaluates RPN with different structures and fea- tures and these results are compared with state-of- the-art trackers in DSTC-3. Rule-based models, statistical models and mixed models performance in cases where testing parser mismatches training parser are also compared. Finally, section 6 con- cludes the paper. </chunk></section><section><heading>2 Rule-based and Statistical Models for DST </heading><chunk>The results of the DSTCs demonstrated the power of statistical approaches, such as Maximum En- tropy (MaxEnt) (Lee and Eskenazi, 2013), Con- ditional Random Field (Lee, 2013), Deep Neural Network (DNN) (Sun et al., 2014b), and Recurrent Neural Network (RNN) (Henderson et al., 2014d). However, statistical approaches have some dis- advantages. For example, statistical approaches sometimes show large variation in performance and poor generalisation ability because of lack of data (Williams, 2012). Moreover, statistical models usually have a complex model structure and complex features, and thus can hardly achieve portability and interpretability. In addition to statistical approaches, rule-based approaches have also been investigated in DSTC due to their efficiency, portability and inter- pretability and some of them showed good perfor- mance and generalisation ability in DSTC (Zilka et al., 2013; Wang and Lemon, 2013). However, the performance of rule-based mod- els is usually not competitive to the best statis- tical approaches. Furthermore, a general way is lacking to design rule-based models with prior knowledge and their performance can hardly be improved when training data is available. </chunk></section><section><heading>3 Bridging Rule-based models and statistical models </heading><chunk>There are two ways of bridging rule-based ap- proaches and statistical approaches. One starts from rule-based models and uses data-driven ap- proaches to find a good rule, while the other one is a statistical model taking advantage of prior knowledge and constraints. </chunk></section><section><heading>3.1 Constrained Markov Bayesian Polynomial </heading><chunk>Constrained Markov Bayesian Polynomial (CMBP) (Sun et al., 2014a; Yu et al., 2015) takes the first way of bridging rule-based models and statistical models. Several probability features extracted from SLU results shown below are used in CMBP for each slot (Sun et al., 2014a; Yu et al., 2015): P + t (v): sum of scores of SLU hypotheses in- forming or affirming value v at turn t P t (v): sum of scores of SLU hypotheses denying or negating value v at turn t P + t (v) = v / {v,None} P + t (v ) P t (v) = v / {v,None} P t (v ) b t (v): belief of the value being v at turn t b r t : probability of the value being N one (the value not mentioned) at turn t. Because slots and values are assumed indepen- dent in CMBP. To simplify the notation, these fea- tures are denoted as P + t , P t , P + t , P t , b r t , b t in the rest of this paper. 296 With these probability features , a CMBP model is defined by b t =P P + t , P t , P + t , P t , b r t1 , b t1 s.t. constraints (1) where the P is a multivariate polynomial function defined as P(x 1 , , x D ) = 0k 1 knD g k 1 , ,kn 1in x k i (2) where k i is an index into input variables. n called order of the CMBP is the order of the polynomial, D denotes the number of inputs with x 0 = 1 and g is the parameter of CMBP. In CMBP, prior knowledge or intuition is en- coded by constraints in equation (1). For example, intuition that goal belief should be unchanged or positively correlated with the positive scores from SLU can be written to a constraint: P(P + t+1 , P t+1 , P + t+1 , P t+1 , b r t , b t ) P + t+1 0 (3) Further, these constraints are approximated to linear forms (Sun et al., 2014a; Yu et al., 2015). With a set of linear constraints, integer lin- ear programming can be used to get the integer parameters which satisfy the relaxed constraints. Then the tracking accuracy of each parameters can be evaluated and the best one is picked out. Hill-climbing can further be used to extend the best integer-coefficient CMBP to real-coefficient CMBP (Yu et al., 2015). Note that in practice order 3 (n=3) is used to bal- ance the performance and the complexity (Sun et al., 2014a; Yu et al., 2015). 3-order CMBP has achieved state-of-the art-performance on DSTC- 2/3. </chunk></section><section><heading>3.2 Recurrent Polynomial Network </heading><chunk>Recurrent Polynomial network (Sun et al., 2015) takes the second way to bridge rule-based and sta- tistical models. It is a computational network and a statistical framework, which takes advantage of prior knowledge by using CMBP to do initializa- tion. RPN contains two types of nodes, input node or computational node. Every node x has a value at every time t, denoted by u (t) x . The values of computational nodes at time t are evaluated using the nodes values at time t and the nodes values at time t 1 as inputs just like Recurrent Neural Networks (RNNs). Two types of edges are introduced to denote the time relation between linked nodes. A node at time t takes the value of a node at time t 1 as input when they are connected by type-1 edges, while type-2 edges indicate that a node at time t takes the value of a node at time t. Let I x denote the set of nodes which are con- nected to node x by type-1 edges. Similarly, let I x denote the set of nodes which are connected to node x by type-2 edges. Generally, three types of computational node are used in RPN, which are sum node, product node and activation node. Sum node: For sum node x at time t, its value u (t) x is the weighted sum of its inputs: u (t) x = yIx w x,y u (t1) y + y Ix w x,y u (t) y (4) where w x,y , w x,y R are the weights of edges. Product node: For product node x at time t, its value u (t) x is the product of its inputs. Note that there may be multiple edges connecting from node y to node x. Then node ys value should be multiplied to u (t) x multiple times. Formally, let M x,y and M x,y be the multiplic- ity of the type-1 edge yx and the multiplicity of the type-2 edge yx respectively. Node xs value u (t) x is evaluated by u (t) x = yIx u (t1) y Mx,y y Ix u (t) y Mx,y (5) Activation node: As the value of product nodes and sum nodes are not bounded by cer- tain range while the output belief should lie in [0, 1], activation functions are needed to map values from R to some interval such as [0, 1]. An activation function is a univariate func- tion. If node x is an activation node, there is only one type-2 edge linked to it. Sun et al. (2015) investigated several acti- vation functions and proposed an ascending, continuous function sof tclip mapping from R to [0, 1] which is linear on [, 1 ] with being a small value. 297 Note that w, w are the only parameters in RPN while M x,y and M x,y are constant given the struc- ture of RPN and each node can be used as output node in RPN. 3.2.1 Basic Structure A basic 3-layer RPN shown in figure 1 is intro- duced here to help understand the correlation be- tween 3-order CMBP and RPN. i i i i1 i i i i + i i i i i i i i + i i i i 1 i i i i i i i i+1 + i i i i+1 i i i i+1 + i i i i+1 1 i i i i i i i i+1 i i, i i i i, i i Figure 1: RPN for DST. (Here + nodes are sum nodes, nodes are product nodes) For simplicity, (l, i) is used to denote the index of the i-th node in the l-th layer. Then each layer is defined as follows: First layer / Input layer: In this layer, input nodes correspond to the variables in equation (1), i.e. the value of 6 input nodes u (t) (0,0) u (t) (0,5) are the same as variables b t1 , P + t , P t , P + t , P t , 1 in equation (1). Feature b r t1 which is belief of the value at time t 1 being N one is not used here to make the RPN structure clear and com- pact. Experiments show that performance of CMBP without feature b r t1 would not de- grade. It is not used by CMBP mentioned in the rest of paper either. Second layer: Every product node x in the second layer corresponds to a monomial in equation (2). To express different monomi- als, each triple of input nodes (1, k 1 ), (1, k 2 ), (1, k 3 )(0 k 1 k 2 k 3 5) is enumer- ated to link to a product node x = (2, i) in the second layer and u (t) x = u (t) (1,k 1 ) u (t) (1,k 2 ) u (t) (1,k 3 ) . Third layer: There is only one sum node (3, 0) in the third layer corresponding to the belief value calculated by a polynomial. With the parameters set according to g k 1 ,k 2 ,k 3 in equation (2), the value u (t) (3,0) is equal to b t outputted by equation (1). It is the only out- put node in this structure. From the explanation of basic structure in this section, it can be easily observed that a CMBP can be used to initialize RPN and thus RPN can achieve at least the same results with CMBP. So prior knowledge and constraints are used to find a suboptimum point in RPN parameter space and RPN as a statistical approach, can further optimize its parameters. Hence, RPN is a way of bridging rule-based models and statistical models. 3.2.2 Complete Structure It is easy to add features to RPN as a statistical model. In the work of Sun et al. (2015), 4 more features about user dialogue acts and machine acts are introduced. A new sum node x = (3, 1) in the third layer is introduced to capture some property across turns just like belief b t . Like the node (3, 0) that outputs belief in the same layer, node (3, 1) takes input from every product node in the second layer and is used as input features at next time. Further, to map the output belief to [0, 1], ac- tivation nodes with sof tclip() as their activation function are introduced. The complete structure with the activation func- tion, 4 more features and the new recurrent con- nection is shown in figure 2. i i i i i i i i+1 i i 1 (i i) i i 2 (i i) i i 8 (i i) i i 9 (i i) i i 1 (i i+1) i i 2 (i i+1) i i 8 (i i+1) i i 9 (i i+1) Figure 2: RPN with new features and more com- plex structure for DST (Sigmoid nodes mean acti- vation) The relation between a 3-order CMBP and the basic structure is shown in section 3.2.1. Similarly, the complete structure can also be initialized using CMBP by setting the weights of edges that do not appear in the basic structure to 0. </chunk></section><section><heading>3.3 Complex RPN Structure </heading><chunk>We next exam RPNs power of utilizing more fea- tures, multiple activation functions and a deeper 298 structure with two interesting explorations on RPN structure are shown in this section. Although these extensions do not yield better results, this section covers these extensions to show the flexibility of the RPN approach. 3.3.1 Complex Structure Firstly, to express a 4-order polynomial, simply using the structure shown in figure 2 with in- degree of nodes in the second layer increased to 4 would be sufficient. However, it can be ex- pressed by a more compact RPN structure. To simplify the explanation, the example RPN ex- pressing 1 (1 (b t1 ) 2 )(1 (P + t ) 2 ) is shown in figure 3. i i i i1 i i i i + 1 i i i i i i i i i i i i+1 + 1 i i i i+1 0 0 0 -1 0 1 0 1 0 0 0 -1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 -1 0 1 0 1 0 0 0 -1 0 0 0 0 0 1 1 0 0 0 0 1 1 (i ii i1) 2 1 (i ii i + ) 2 1 Figure 3: RPN for polynomial 1 (1 (b t1 ) 2 )(1 (P + t ) 2 ) In figure 3, the first layer is used for input, and the values of the product nodes in the second layer are equal to the products of two features such as (b t1 ) 2 , b t1 P + t , (P + t ) 2 and so on. Every sum node in the third layer can express all the possi- ble 2-order polynomial of features with weights set accordingly. In figure 3, the values of the three sum nodes are 1 (b t1 ) 2 , 1 (P + t ) 2 and 1 re- spectively. Then similarly, with another product nodes layer and sum nodes layer, the value of the output node in the last layer equals the value of the 4-order polynomial (1 (b t1 ) 2 )(1 (P + t ) 2 ). The complete RPN structure with same fea- tures shown in figure 2, the new recurrent connec- tion and activation nodes that expresses 4-order CMBPs can be obtained similarly. With limited sum nodes in the third layer, the complexity of the model is much smaller than us- ing a structure shown in figure 2 with product nodes in-degree increased to 4 and increasing the number of product nodes accordingly. 3.3.2 Complex Features Secondly, RNN proposed by Henderson et al. (2014c) uses n-gram of ASR results and ma- chine acts. Similar to that, features of n-gram of ASR results and machine acts are also investigated in RPN. Since RPN used in this paper is a binary classification model and assumes slots indepen- dent of each other, the n-gram features proposed by Henderson et al. (2014c) are modified in this paper by removing/merging some features to make the features independent of slots and values. When tracking slot s and value v, the sum of confidence scores of ASR hypothesises of the following cases are extracted: V : confidence score of ASR hypothesises where value v appears V : confidence score of ASR hypothesises where values other than v appear V r : confidence score of ASR hypothesises where no value appear Similar features for slots can be extracted. Then by looking at both slot and value features for ASR results, we can get the combination of conditions of slots and values. n-gram features of machine acts about the tracking slot and value are also used as features. For example, given machine acts hello() | inform(area=center) | inform(food=Chinese) | request(name), for slot food and value Chinese, the n-gram machine act features are hello, inform, request, inform+slot, inform+value, inform+slot+value, slot, value, slot+value. Features such as request(name) are about slot name and hence request+slot are not in the feature list. To combine RPN with RNN proposed by Hen- derson et al. (2014c), input nodes of these n-gram features are not linked to product nodes in the sec- ond layer. Instead, a layer of sum nodes followed by a layer of activation nodes with sigmoid ac- tivation function, which are equivalent to a layer of neurons are introduced. These activation nodes are linked to sum nodes in the third layer just like product nodes in the second layer. The structure is illustrated by figure 4 clearly. 299 i i i i i i 1 (i i) i i 2 (i i) i i 8 (i i) i i 9 (i i) Additional features extracted from ASR and machine acts Figure 4: RPN structure combined with RNN fea- tures and structures Experiments in section 5 show that these two structures do not yield better results when initial- ized randomly or initialized using 3-order CMBPs, although the model complexity increases a lot. This indicates the briefness and effectiveness of the simple structure shown in figure 2. </chunk></section><section><heading>4 Uncertainty in SLU </heading><chunk>In an end-to-end dialogue system, there are two challenges in spoken language understanding: ASR errors and insufficient in-domain dialogue data. ASR errors make information contained in the users utterance distorted or even missed. Thank- fully, statistical approaches to SLU, trained on la- beled in-domain examples, have been shown to be relatively robust to ASR errors. (Mairesse et al., 2009). Even with an effective way to get SLU robust to ASR errors, it is hard to implement these SLUs for a new domain due to insufficient labelled data. In DSTC-3, only little data of new dialogue domain is provided. Following the work of Zhu et al. (2014), the fol- lowing steps are used to handle the two challenges stated above: Data generation: with sufficient data in restaurants domain in DSTC-2, data on tourists domain using ontology of DSTC-3 can be generated. Utterance patterns of data in the original domain are used to generate data for the new domain of DSTC-3. After preparing both the original data in DSTC-2 and the generated data of DSTC-3, a more general parser for these two domains can be built. ASR error simulation: after data generation, ASR error simulation (Zhu et al., 2014) is needed to make the prepared data resemble ASR output with speech recognition errors to train a parser robust to ASR errors. With a simple mapping from the pattern of transcrip- tion to the corresponding patterns of ASR n- best hypotheses learned from existing data and phone-based confusion for slot-values, pseudo ASR n-best hypotheses can be ob- tained. Note that methods proposed by Zhu et al. (2014) only do ASR error simulation for generated data in domain of DSTC-3 and leave the original data in DSTC-2 as its origi- nal ASR form,which may introduce the dif- ference in the distribution between training data and testing data on two different do- mains for the tracker. So ASR error is sim- ulated in data on both domains instead. Training: Using the data got from the previous steps, a statistical parser can be trained (Henderson et al., 2012). By varying the fraction of simulated vs. real data, and the simulated error rate, prior expectations about operating conditions can be expressed. Although a semantic parser with state-of-the- art techniques can achieve good performance in some degree, parsing without any error is impossi- ble because it is typical that a semantic parser gets high performance in speech patterns existing in the training dataset, while it fails to predict the correct semantics for some utterances unseen in training dataset. So it is common for SLU performance to differ significantly between training and test con- ditions in real world end-to-end systems. It has been widely observed that SLU influ- ences state tracking greatly because the confidence scores of SLU hypotheses are usually the key in- puts for dialogue state tracking. When these confi- dence scores become unreliable, the performance of tracker is sure to degrade. Studies have shown that it is possible to improve SLU accuracy as compared to the live SLU in the DSTC data (Zhu et al., 2014; Sun et al., 2014b). Hence, most of the state-of-the-art results from DSTC-2 and DSTC- 3 used refined SLU (either explicitly rebuild a SLU component or take the ASR hypotheses into the trackers (Williams, 2014; Sun et al., 2014b; 300 Henderson et al., 2014d; Henderson et al., 2014c; Kadlec et al., 2014; Sun et al., 2014a)). Kadlec et al.(2014) gets a tracking accuracy improvement of 7.6% when they use SLU refined by themselves instead of organiser-provided live SLU. In semantic parser mismatch condition, the ac- curacy of state tracking can degrade badly. Mis- matched SLU problem is a main challenge in DST. Trackers under mismatched SLU conditions are investigated in this paper. </chunk></section><section><heading>5 Experiments </heading></section><section><heading>5.1 RPN with Different Structures </heading><chunk>In this section, the performance of three structures shown in this paper is compared and RPN with the simple structure is evaluated on DSTC-3 and compared with the best submitted trackers. Only joint goal accuracy which is the most difficult task of DSTC-3 is of interest. Note that the integer- coefficient CMBP with the best performance on DSTC-2 is used to initialize RPN. As it is stated in section 4, SLU designed in this paper focuses on domain extension, so trackers are only evaluated on DSTC-3. Order n-gram features Acc L2 3 No 0.652 0.540 4 No 0.648 0.541 4 Yes 0.648 0.541 Table 1: Performance comparison among RPNs with three structures on dstc3eval The RPN structures that express 3-order CMBP, 4-order CMBP without n-gram features and 4- order CMBP with n-gram features are evaluated. Acc is the accuracy of trackers 1-best joint goal hypothesis, the larger the better. L2 is the L2 norm between correct joint goal distribution and distri- bution tracker outputs, the smaller the better. It can be seen from table 1 that the simple struc- ture yields the best result. Note that parser used here is explained in work (Zhu et al., 2014). Ex- periments of the mismatched SLU case also use this SLU for training. For DSTC-3, it can be seen from table 2, RPN trained on DSTC-2 can achieve state-of-the-art performance on DSTC-3 without modifying track- ing method, outperforming all the submitted track- ers in DSTC-3 including the RNN system. Note that the simple structure is used here with SLU refined described in section 4. We picked the best practical one on dstc2-test among SLUs intro- System Approach Rank Acc L2 Baseline* Rule 6 0.575 0.691 Henderson et al. (2014c) RNN 1 0.646 0.538 Kadlec et al. (2014) Rule 2 0.630 0.627 Sun et al. (2014a) Int CMBP 3 0.610 0.556 RPN RPN 0.5 0.660 0.518 Table 2: Performance comparison among RPN, real-coefficient CMBP and best trackers of DSTC- 3 on dstc3eval. Baseline* is the best results from the 4 baselines in DSTC3. duced in the following section as the training SLU and testing SLU. </chunk></section><section><heading>5.2 RPN with Mismatched Semantic Parsers </heading><chunk>As section 4 stated, SLU is the input module for dialogue state tracking whose confidence score is usually directly used as probability features and hence has tremendous effect on trackers. Handling mismatched semantic parsers is a main challenge to DST. In this section, different tracking methods are evaluated when there is a mismatch between train- ing data and testing data. More specifically, dif- ferent tracking models are trained with the same fixed SLU and tested with different SLUs. Three main categories of tracking models are investigated: rule-based models, statistical models and mixed models. MaxEnt (Sun et al., 2014b) is a statistical model. HWU baseline (Wang, 2013) is selected as a competitive rule-based model. CMBP and RPN are mixed models. Four type of SLUs with different levels of per- formance are used: </chunk></section><section><heading>1 Original: SLU results provided by DSTC-3 organizer. </heading><chunk>2 Train: SLU introduced in section 4 with k(k = 25, 50) percent training data adding ASR error simulation and parsed on ASR- hypotheses. </chunk></section><section><chunk>3 Combined: SLU combining the Original type SLU and Train type SLU using averaging.  4 Transcript: SLU introduced in section 4 with k percent training data adding ASR error sim- ulation and parsed on transcription. This setup assumes an oracle speech recognizer: it is not practical, and is included only for com- parison. 301 It has been shown that the organiser-provided live SLU can be improved upon and so it is used as the worst SLU in the following comparison. Past work has shown that trained parser gets a per- formance improvement when combined with the one the organiser provided (Zhu et al., 2014). Us- ing transcription for parsing gives a much more reliable SLU results than using ASR hypothe- ses. So generally speaking, performance of SLUs of different types is quite distinguished to each other. Six different SLUs whose performance score shown in table 3 are investigated. SLU type ASR error ICE Fscore Precision Recall Original - 1.719 0.824 0.852 0.797 Train 25% 1.441 0.836 0.863 0.811 50% 1.425 0.837 0.862 0.813 Combined 25% 1.241 0.834 0.870 0.801 50% 1.235 0.835 0.869 0.803 Transcript 50% 0.893 0.915 0.956 0.877 Table 3: Performance of six different SLUs Note that ASR error here is the percent of train- ing data with ASR error simulation when training SLU. The Item Cross Entropy (ICE) (Thomson et al., 2008) between the N-best SLU hypotheses and the semantic label assesses the overall quality of the semantic items distribution, and is shown to give a consistent performance ranking for both the confidence scores and the overall correctness of the semantic parser (Zhu et al., 2014). SLU with the lower ICE has better performance. Precision and recall are evaluated using only SLUs 1-best hypothesis where ICE takes all hy- pothesises and their confidence score into consid- eration. In results shown in figure 5, the training dataset for tracker is fixed, while testing dataset is out- putted by different SLUs. The X-axis gives the SLU ICE and Y-axis gives the tracking accuracy on DSTC3-test. It can be observed that RPN achieves highest accuracy on every SLU among rule-based models, statistical models and mixed models. Thus, RPN shows its robustness on mis- matched semantic parsers, which demonstrates the power of using both prior knowledge and being a statistical approach. After evaluating the mismatched case, the matched case is also tested. When training dataset and testing dataset are outputted by the same SLU, RPN also outperforms all other models, shown in figure 6. It can be observed that RPN achieves the high- est accuracy among RPN, CMBP, MaxEnt, and 0.55 0.6 0.65 0.7 0.75 0.8 0.8 1 1.2 1.4 1.6 1.8 HWU CMBP MaxEnt RPN ICE Accuracy Figure 5: Trackers performances with mis- matched semantic parsers 0.55 0.6 0.65 0.7 0.75 0.8 0.8 1 1.2 1.4 1.6 1.8 HWU MaxEnt RPN ICE Accuracy Figure 6: Trackers performances with matched semantic parser HWU baseline whether there is a mismatch be- tween training SLU and testing SLU or not. 6 Conclusion Recurrent Polynomial Network demonstrated in this paper is a recent framework to bridge rule- based and statistical models. Several networks are explored and the simple structures perfor- mance outperforms others. Experiments show that RPN outperforms many state-of-the-art trackers on DSTC-3 and RPN performs best on all SLUs with mismatched SLU. Acknowledgments This work was supported by the Program for Pro- fessor of Special Appointment (Eastern Scholar) at Shanghai Institutions of Higher Learning, the China NSFC project No. 61222208 and the Chun-Tsung Program of SJTU. We thank Jason Williams for reviewing and providing suggestions to this paper. 302 Appendix Activation function An activation function sof tclip() is a combina- tion of logistic function and clip function. Let denote a small value such as 0.01, de- note the offset of sigmoid function such that sigmoid ( 0.5 + ) = . sigmoid function here is defined as sigmoid(x) = 1 1 + e x (6) The softclip function is defined as sof tclip(x) sigmoid (x 0.5 + ) if x x if &lt; x &lt; 1 sigmoid (x 0.5 ) if x 1 (7) It is a non-decreasing, continuous function, which is linear on [, 1 ]. Its derivative is de- fined as follows: sof tclip(x) x sigmoid(x0.5+) x if x 1 if &lt; x &lt; 1 sigmoid(x0.5) x if x 1 (8) Training Backpropagation through time (BPTT) using mini-batch is used to train the network with batch size 50. Gradients of weights are calculated and accumulated within each batch. Gradients com- puted for each timestep are propagated to the first timestep. Mean squared error (MSE) is used as the criterion to measure the distance of the output belief to the correct belief distribution. Derivative calculation Let (t) x be the partial derivative of the cost func- tion over value of node x, i.e., (t) x = L ux . Sup- pose node x = (d, i) is a sum node, then when node x passes its error, the error of child node y I x is updated as (t) y = (t) y + L u (t) x u (t) x u (t) y = (t) y + (t) x w x,y (9) Similarly, error of node y I x is updated as (t) y = (t) y + L u (t) x u (t) x u (t1) y = (t) y + (t) x w x,y (10) Suppose node x = (d, i) is a product node, then when node x passes its error, error of node y I x is updated as (t) y = (t) y + L u (t) x u (t) x u (t) y = (t) y + (t) x M x,y u (t) y Mx,y1 z Ix{y} u (t) z Mx,z zIx u (t1) z Mx,z (11) Similarly, error of node y I x is updated as (t) y = (t) y + L u (t) x u (t) x u (t1) y = (t) y + (t) x M x,y u (t1) y Mx,y1 z Ix u (t) z Mx,z zIx{y} u (t1) z Mx,z (12) References Matthew Henderson, Milica Gasic, Blaise Thomson, Pirros Tsiakoulis, Kai Yu, and Steve Young. 2012. Discriminative spoken language understanding us- ing word confusion networks. In SLT, pages 176 181. Matthew Henderson, Blaise Thomson, and Jason D. Williams. 2014a. The second dialog state track- ing challenge. In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 263272, Philadel- phia, PA, U.S.A., June. Association for Computa- tional Linguistics. 303 Matthew. Henderson, Blaise. Thomson, and Jason D. Williams. 2014b. The third dialog state tracking challenge. In Proceedings of IEEE Spoken Lan- guage Technology Workshop (SLT), December. Matthew. Henderson, Blaise. Thomson, and Steve. Young. 2014c. Robust dialog state tracking using delexicalised recurrent neural networks and unsu- pervised adaptation. In Proceedings of IEEE Spoken Language Technology Workshop (SLT), December. Matthew Henderson, Blaise Thomson, and Steve Young. 2014d. Word-based dialog state track- ing with recurrent neural networks. In Proceedings of the 15th Annual Meeting of the Special Inter- est Group on Discourse and Dialogue (SIGDIAL), pages 292299, Philadelphia, PA, U.S.A., June. As- sociation for Computational Linguistics. Rudolf Kadlec, Miroslav Vodoln, Jindrich Libovick, Jan Macek, and Jan Kleindienst. 2014. Knowledge- based dialog state tracking. In Proceedings 2014 IEEE Spoken Language Technology Workshop, South Lake Tahoe, USA, December. Sungjin Lee and Maxine Eskenazi. 2013. Recipe for building robust spoken dialog state trackers: Dialog state tracking challenge system description. In Pro- ceedings of the SIGDIAL 2013 Conference, pages 414422, Metz, France, August. Association for Computational Linguistics. Sungjin Lee. 2013. Structured discriminative model for dialog state tracking. In Proceedings of the SIGDIAL 2013 Conference, pages 442451, Metz, France, August. Association for Computational Lin- guistics. Franc  ois Mairesse, Milica Gasic, Filip Jurc  cek, Simon Keizer, Blaise Thomson, Kai Yu, and Steve Young. 2009. Spoken language understanding from un- aligned data using discriminative classification mod- els. In Proceedings of ICASSP. Kai. Sun, Lu. Chen, Su. Zhu, and Kai. Yu. 2014a. A generalized rule based tracker for dialogue state tracking. In Proceedings of IEEE Spoken Language Technology Workshop (SLT), December. Kai Sun, Lu Chen, Su Zhu, and Kai Yu. 2014b. The SJTU system for dialog state tracking challenge 2. In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dia- logue (SIGDIAL), pages 318326, Philadelphia, PA, U.S.A., June. Association for Computational Lin- guistics. Kai Sun, Qizhe Xie, and Kai Yu. 2015. Recur- rent polynomial network for dialogue state tracking. submitted to Dialogue and Discourse. Blaise Thomson, Kai Yu, Milica Gasic, Simon Keizer, Francois Mairesse, Jost Schatzmann, and Steve Young. 2008. Evaluating semantic-level confi- dence scores with multiple hypotheses. In INTER- SPEECH, pages 11531156. Zhuoran Wang and Oliver Lemon. 2013. A sim- ple and generic belief tracking mechanism for the dialog state tracking challenge: On the believabil- ity of observed information. In Proceedings of the SIGDIAL 2013 Conference, pages 423432, Metz, France, August. Association for Computational Lin- guistics. Zhuoran Wang. 2013. HWU baseline belief tracker for dstc 2 &amp; 3. Technical report, October. Jason D. Williams and Steve Young. 2007. Par- tially observable markov decision processes for spo- ken dialog systems. Computer Speech &amp; Language, 21(2):393422. Jason Williams, Antoine Raux, Deepak Ramachan- dran, and Alan Black. 2013. The dialog state track- ing challenge. In Proceedings of the SIGDIAL 2013 Conference, pages 404413, Metz, France, August. Association for Computational Linguistics. Jason D. Williams. 2012. Challenges and opportu- nities for state tracking in statistical spoken dialog systems: Results from two public deployments. Se- lected Topics in Signal Processing, IEEE Journal of, 6(8):959970. Jason D. Williams. 2014. Web-style ranking and SLU combination for dialog state tracking. In Proceed- ings of the 15th Annual Meeting of the Special Inter- est Group on Discourse and Dialogue (SIGDIAL), pages 282291, Philadelphia, PA, U.S.A., June. As- sociation for Computational Linguistics. Kai Yu, Kai Sun, Lu Chen, and Su Zhu. 2015. Con- strained markov bayesian polynomial for efficient dialogue state tracking. submitted to IEEE Trans- actions on Audio, Speech and Language Processing. Su Zhu, Lu Chen, Kai Sun, Da Zheng, and Kai Yu. 2014. Semantic parser enhancement for dialogue domain extension with little data. In Proceedings of IEEE Spoken Language Technology Workshop (SLT), December. Lukas Zilka, David Marek, Matej Korvas, and Filip Ju- rcicek. 2013. Comparison of bayesian discrimina- tive and generative models for dialogue state track- ing. In Proceedings of the SIGDIAL 2013 Confer- ence, pages 452456, Metz, France, August. Asso- ciation for Computational Linguistics. 304 </chunk></section></sec_map>