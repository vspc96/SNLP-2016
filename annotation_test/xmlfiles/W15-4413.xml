<sec_map><section><chunk>Proceedings of The 2nd Workshop on Natural Language Processing Techniques for Educational Applications, pages 8793, Beijing, China, July 31, 2015. c 2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing Salinlahi III: An Intelligent Tutoring System for Filipino Language Learning Ralph Vincent Regalado , Michael Louie Bonon, Nadine Chua, Rene Rose Pinera, Shannen Rose Dela Cruz Center for Language Technologies De La Salle University, Manila ralph.regalado@delasalle.ph, {michael.bonon, chuanadine}@gmail.com, {renepinera, shannenrose.delacruz}@yahoo.com </chunk></section><section><heading>Abstract </heading><chunk>Heritage language learners are learners of the primary language of their parents which they might have been exposed to but have not learned it as a language they can fluently use to communicate with other people. Salinlahi, an Interactive Learning Environment, was developed to teach these young Filipino heritage learn- ers about basic Filipino vocabulary while Salinlahi II included a support for collab- orative learning. With the aim of teaching learners with basic knowledge in Filipino we developed Salinlahi III to teach high- er level lessons focusing on Filipino grammar and sentence construction. An internal evaluation of the system has shown that the user interface and feed- back of the tutor was appropriate. More- over, in an external evaluation of the sys- tem, experimental and controlled field tests were done and results showed that there is a positive learning gain after us- ing the system. </chunk></section><section><heading>1 Introduction </heading><chunk>The idea behind Intelligent Tutoring Systems is letting a computer simulate a sophisticated human tutor and be able to use a teaching strate- gy appropriate for each student (Murray, 1999) (Massey, Psotka, &amp; Mutter, 1988). According to (Kassim, Kazi, &amp; Ranganath, 2004), there are four important elements that must be present in instructional systems. These four are the tutor, the student, the domain knowledge to be learned by the student, and lastly, the computer itself. These four elements were the basis of the func- tional model of an ITS according to (Kassim, Kazi, &amp; Ranganath, 2004) which consists of the following: expert module, tutoring module, stu- dent model and user interface module. This func- tional model is accepted as a standard in building the system architecture of ITSs (Polson &amp; Rich- ardson, 1988). Many ITSs have been built for different fields (such as cardiovascular physiolo- gy, algebra, language learning, electronics trou- bleshooting etc). Some of these ITSs are Au- toTutor and ELM-ART. AutoTutor, developed by (Graesser et al., 2004), features tutoring done in natural language dialogue while ELM-ART, developed by (Brusilovsky, Schwarz, &amp; Weber, 1996), pioneered ITSs in the World Wide Web. Intelligent Tutoring Systems served as the in- spiration in developing Salinlahi III. Unlike the two previous iterations of Salinlahi which are purely Interactive Learning Environments, Salin- lahi III was designed from the ITS perspective. In the previous systems, students have the free- dom to choose which lessons to take while in Salinlahi III, students are directed toward a se- quential progress of lessons by a tutor which is the system itself. The lessons in this system are structured in terms of content and skill complexi- ty, starting from basic concepts to lessons deal- ing with construction of basic Filipino sentences. The tutor decides when to advance to the next lesson based on the student's performance in the exercises given in every lesson. These exercises are namely Translation Exercise and Creation Exercise. The exercises were designed as a dia- logue type of exercise between the tutor and the student. However, it is only in the Translation Exercise where the tutor will guide the student to attain the correct answer by giving feedback on his or her current answers. The feedback given by the tutor is done in natural language inspired by AutoTutor. This is made possible through the use of template-based Natural Language Genera- tion (NLG), a technique used in generating con- tent in natural language. 87 Figure 1. Screenshot of the Translation Exercise Salinlahi III focuses on teaching basic Filipino grammar whereas the two previous iterations focus on Filipino vocabulary. This change in the domain of knowledge is a solution to accommo- date learning needs of older students with a basic knowledge of Filipino vocabulary. These stu- dents are assumed to be at the range of fourteen (14) to seventeen (17) years old. </chunk></section><section><heading>2 System Architecture </heading><chunk>Figure 2. Salinlahi III System Architecture The system architecture of Salinlahi III fol- lows the functional model of an ITS by (Kassim, Kazi, &amp; Ranganath, 2004). Based from this mod- el, Salinlahi III has been designed with four main modules namely, User Interface Module, Expert Module, Tutoring Module, and Student Module. </chunk></section><section><heading>2.1 User Interface Module </heading><chunk>The User Interface Module provides lesson and exercises to the user. It is also responsible for passing the user input to the different system modules. </chunk></section><section><heading>2.2 Expert Module </heading><chunk>The Expert Module does the analysis of the users input. This module contains two different analyzers for the exercises. The first input ana- lyzer is for the Translation Exercise. This ana- lyzer checks the translation of the student with the corresponding expected translation by the tutor. After analysis, the tutor will come up with its assessment. The second analyzer is for the Creation Exercise. This analyzers main job is to parse the students input and check if the student has successfully applied in his or her answer what is being discussed in the current lesson. This module also does different functions such as the computation of the Levenshtein distance, to- kenization of strings and the Realiser which pre- pares the tutors feedback. </chunk></section><section><heading>2.3 Tutoring Module </heading><chunk>The Tutoring Module handles the processes of the exercises. For the Translation Exercise, the tutors move is managed. This move, as dis- cussed earlier in Section 2.3, is based from the assessment of the tutor on the students answer. The assessment is produced in the Expert Mod- ule. This module includes (but is not limited to) 88 keeping track of the chances of the student, man- aging the number of items given, updating the student model, managing the turns between the student and the tutor, communicating with the Expert Module for analysis, management of the student model, and the production of evaluation after the exercises. </chunk></section><section><heading>2.4 Student Module </heading><chunk>The Student Module contains student model. It is in this module that the tree for the student model is handled. This module is accessed by the Tutoring Module to update the student model based on the students performance in the exer- cises. It is also accessed when the evaluation for the student is needed. The evaluation is generat- ed based from the data in the nodes of the student model. </chunk></section><section><heading>3 System Exercises </heading><chunk>In every lesson, students are given exercises to test their learning on the current lesson they are studying which are Translation Exercise and Creation Exercise. This phase where students answer exercises corresponds to the "Response" stage in the Initial- Response-Evaluation (IRE) model mentioned by (Murray, 1999). According to the IRE model, the Response stage is where students are expected to have gained knowledge or skills after being exposed to instructions. Fur- thermore, in this stage, students are expected to have learned how to translate new knowledge or skills into practice (Murray, 1999). </chunk></section><section><heading>3.1 Translation Exercise </heading><chunk>Students go through Translation Exercise first before the Creation Exercise. In Translation Ex- ercise, the learner is given a certain number of phrases or sentences he or she needs to translate to Filipino in the context of the lesson where it belongs. The exercise begins with the tutor giv- ing instructions to learners followed by giving the first problem. For each problem, the learner is given at most three chances to answer correct- ly. In case the learner does not get it right at the last chance, the score will be based on his or her last answer. As the learner tries to answer the problem, the tutor in turn gives the appropriate feedback in order to facilitate learning as seen in Figure 1. After the student enters his or her answer, the tutor immediately reflects and gives feedback based from the students answer. It can be seen in Figure 3 that the tutor immediately tries to make its move after the students input. The moves of the tutor are not random. It makes its move based from its assessment on the students answer. Figure 3 shows the flow on how the tu- tors feedback is formed. Figure 3. Flow on how the tutor comes up with a feedback 3.1.1 The Assessment of Students Answer i ii ii ii ii ii ii ii ii ii i  i ii ii ii ii i = i ii ii ii ii ii i hi ii ii ii ii ii ii i i ii ii ii ii i i ii ii ii ii ihi ii ii i i ii ii ii ii ii ii ii i i ii i i ii ii i Equation 1. Difference Value In the Translation Exercise, there are four pos- sible assessments for the students answer. These are Correct, Near the Answer, Incorrect and Cannot be understood. Correct is the assessment that the tutor would come up with when the student gave an answer that exactly matches the expected answer of the tutor. Near the Answer is assessed by the tutor if it sees that the answer is wrong but have analyzed that the student possibly applied a misconception in his or her answer. Near the Answer could also be assessed by the tutor if the computed difference value of the students answer against the ex- pected answer is less than or equal to .30. The formula of the difference value is shown on Equation 1. In Equation 1, LengthOfExpecte- dAnswer corresponds to the number of charac- ters the string, which is the students answer, has. The LevenshteinDistance corresponds to the Levenshtein distance. It is a string metric used to measure how many insertions, substitutions and deletions are required to transform a given string to a target string (Nielsen, 1994). Incorrect on the other hand is assessed by the tutor if the answer is also wrong. However, it only becomes the assessment when the student applied a misconception and the computed dif- ference value exceeds the threshold which is .30. Cannot be understood is the assessment given by the tutor when it sees that the students an- swer is wrong, no misconception was applied and the computed difference value exceeds the threshold. 3.1.2 The Move of the Tutor The move that the tutor should make is based from the assessment of the students answer. The four moves of the tutor are Explain, Warn, State and Produce. All of these moves have different types of feedback. Explain will be the move used 89 when the learners input is Incorrect or Near the Answer. Warn will be the move used when the learners input is Cannot be Understood. This would tell the user to enter a more sensible input. State will be the move used when the learners input is Correct. Produce will be the move to be used to give an exercise to the learn- er. 3.1.3 The Feedback of the Tutor The feedback of the tutor is based from the move that the tutor has to make. The feedbacks are produced using template-based NLG. Under each of the four moves are different templates for the feedback of the tutor. The type of feedback to be given by the tutor also takes into account the number of chances left in the current item. An example of a feedback can be seen on Figure 1. In that scenario (see Figure 1) the tutor used an Explain move. The type of feedback under this move to be used by the tutor would be based from the assessment and the number of chances left. The tutors feedback which is si John, Dojah at Thern is near the answer but I regret to inform you that it is not the correct answer in which your answer actually applied si. You have another chance to answer this item, I hope youll get it. :) . Notice in this scenario, the tutor informed the student his or her answer is wrong but is near to the expected answer. The tutor also tried to show why the answer was wrong by pointing out the misconception applied by the student. Also, since it is the students first time to get a wrong answer in that item, the last part of the message indicates that the tutor tries to give the student a positive feedback to boost up his or her confidence. </chunk></section><section><heading>3.2 Creation Exercise </heading><chunk>In the Creation Exercise, the student is asked by the tutor to construct or create his or her own Filipino phrases or sentences. The phrases or sentences that need to be created would be based from the lessons or sub lessons discussed in the concept learning materials. The tutor would ran- domly pick a sub lesson and ask the user. Unlike the Translation Exercise, in the Creation Exer- cise, the tutor does not give immediate feedback on the students input. The student would only see an overall evaluation after the exercise. 3.2.1 Reflection in Action The Translation Exercise was designed based on reflection in action by (Schon, 1987). Ac- cording to (Schon, 1987) reflection in action is a case where people reflect in the midst of ac- tion. It shows here that it is during the task that the person reflects on what he or she is doing. In accordance to this, the Translation Exercise was designed to help the student to reflect in his or her performance while taking the exercise. The tutor gives feedback to guide the student and make him or her rethink about his or her answer while there is still a chance. There is an immedi- ate feedback whose goal is to let the student im- mediately reflect and react. 3.2.2 Reflection on Action The Creation Exercise was designed with ba- sis on reflection on action by (Schon, 1987). (Schon, 1987) stated that We may reflect on action, thinking back on what we have done in order to discover how our knowing-in-action may have contributed to an unexpected out- come. The Creation Exercise is designed to be taken after the Translation Exercise. This is to allow the student to think on his or her previous actions previously committed during the Transla- tion Exercise. In the Creation Exercise, the stu- dent can think back on his or her actions and re- flect on it based from the feedback of the tutor at that time. Compared to the Translation Exercise, the tutor during the Creation Exercise does not give an immediate feedback to the students in- put. This is to promote self-reflection on the stu- dents part and have a recall about the tutors feedback earlier (in the Translation Exercise). Whatever phrase or sentence the student has cre- ated, this could most likely show how much he or she really knows, without the help of the tutor. </chunk></section><section><heading>4 System Evaluation </heading><chunk>Tests were done to determine whether the sys- tem was able to achieve its main objective, which is to teach Filipino grammar to secondary level heritage language learners. Experts evaluat- ed the system to determine whether the feedback and user interface is appropriate for the target users. Experts also evaluated the system to de- termine whether it can be considered as a poten- tial educational software. Students also tested the first lesson of the system to know whether there was an increase or decrease in their learning. The increase or decrease in learning may also deter- mine the potential of Salinlahi III as an educa- tional software. 90 </chunk></section><section><heading>4.1 Internal Evaluation </heading><chunk>The internal evaluation focused on seeing the system as a potential educational software. The experts who evaluated the system came from different fields User Interface (UI), develop- ment of teaching tools, second/foreign language teaching (experts from this field teaches lan- guages not only Filipino), education, Filipino teaching. The experts evaluated the system based on UI design, feedback, and as a potential educa- tional software Two experts evaluated the system based on the UI design. They did a test over the system and were later given a questionnaire. The question- naire is based from the general principles of in- terface design that was developed by (Nielsen, 1994). The experts gave an average grade of 4.17, which is between excellent and good. Since they evaluated based on general principles in designing the user interface, this means that it is acceptable for all types of target users. However, these experts gave the following recommenda- tions: (1) it would be helpful if there will be a status that would show that the page is loading or that the tutor is typing a message. (2) Instructions should be provided for first time users. (3) The number of chances during the exercise should be made known to the users. In addition, (4) the sys- tem should provide a way to retrieve the pass- word once the user forgets it. An interview was conducted with an expert who evaluated the system based on the tutors feedback. The results of the interview with the expert show that the tutors feedback is appropri- ate for the learners. The expert verified that the messages are gender-neutral and appropriate for the age range of the target users. In addition, the approaches of the tutor are acceptable and over- all the tutor sounds human. However, the expert stated that if the answer falls for the assessment Cannot be Understood, the tutor must inform the student to refer back to the lesson (e.g. Your answer is not within the framework of the discus- sion. Please refer to the review lessons). Three experts evaluated the system as a poten- tial educational software. They were also given a questionnaire after testing the system. These ex- perts gave an over-all average rating of 4.3, which is between excellent and good. With this grade and the average grade under all the criteria given, the system is believed to have passed or has a potential to be an educational software. However, few recommendations was made: (1) the numbers given in the exercises should be in Filipino and not in Spanish, (2) the learning ma- terials should be in Filipino (e.g. using saging instead of banana), and (3) add more Filipino words to the system. One of the systems limita- tion is having a small collection of words. Be- cause of this, the system may have a wrong as- sessment of the learners answer only because the Filipino word used by the learner is not found in the systems collection of words. </chunk></section><section><heading>4.2 External Evaluation </heading><chunk>The external evaluation was done in order to assess how the system affected the learner spe- cifically in determining its performance in teach- ing students. During the said evaluation, a total of twenty-seven students (27), six coming from the De La Salle University and twenty-one (21) came from MIT International School, went through a series of tests illustrated in Figure 2. Students who have not finished the series of tests were excluded from the analysis. Figure 2. Flow of External Evaluation Students were grouped into two: experimental and controlled end-user testing. Students who went through experimental end-user testing were allowed to interact with the system and use it on their own while those who went through con- trolled end-user testing were supervised. Results from both groups were compared to observe whether supervising the students while they use the system affects their scores in the post-test. This was important since previous iterations of Salinlahi did controlled end-user test only. The addition of the uncontrolled group gives a more realistic scenario where most likely there would be no one to supervise the users aside from the system itself and some accompanying docu- ments. In pre-test, post-test, and vocabulary test, stu- dents were asked to translate English words and phrases into Filipino. The scores in pre-tests and post-tests were used to determine whether stu- dents performance increased after using the sys- tem, or in other terms, they had a positive learn- ing gain. Thereby learning gains can be meas- ured using the paired t-test. According to (Shier, 2004), a paired t-test is used to compare two population means where you have two samples in which observations in one sample can be paired with observations in the other sample. Pre-Test	   System	   Test	   Post-Test	   Vocabulary	   Test	   91 Table 1 shows the scores of the students for the pre-test and post-test under the experimental group. As seen in Table 1, scores of twelve (12 approximately 67%) students increased, five of them did not show any increase at all and the score of one student decreased. Using paired t- test on these values, results have shown that there is a significant increase in the scores as de- termined by the value of p which is 0.003. The values obtained in the paired t-test are shown in Table 2. Student No. Pre-Test Score (X) Post-Test Score (Y) Difference (Y-X) 1 0 4 4 2 1 4 3 3 5 7 2 4 4 8 4 5 3 6 3 6 2 4 2 7 2 2 0 8 6 8 2 9 0 0 0 10 2 4 2 11 0 2 2 12 3 7 4 13 1 2 1 14 2 2 0 15 2 2 0 16 4 3 -1 17 0 2 2 18 0 0 0 Table 1. Students pre-test and post-test scores for experimental end-user testing Label Value (X) n 18 Mean Difference 1.666667 Standard Deviation 1.57181 Standard Error of the Mean 0.370479287 t 4.498677054 Degrees of Freedom 17 p-value 0.003 Table 2. Paired t-test values for experimental end- user testing On the other hand, Table 3 shows the scores of the students for the pre-test and post-test under the controlled group. As seen in Table 3, scores of twelve (6 approximately 67%) students in- creased, two of them did not show any increase at all and the score of one student decreased. Us- ing paired t-test on these values, results have shown that there is a significant increase in the scores as determined by the value of p which is 0.0325. The values obtained in the paired t-test done for this group are shown in Table 4. Student No. Pre-Test Score (X) Post-Test Score (Y) Difference (Y-X) 1 0 2 2 2 0 4 4 3 6 7 1 4 6 8 2 5 0 5 5 6 6 8 2 7 7 6 -1 8 8 8 0 9 7 7 0 Table 3. Students pre-test and post-test scores for controlled end-user testing Label Value (X) n 9 Mean Difference 1.666666667 Standard Deviation 1.936491673 Standard Error of the Mean 0.645497224 t 2.581988897 Degrees of Freedom 8 p-value 0.0325 Table 4. Paired t-test values for controlled end-user testing </chunk></section><section><heading>5 Conclusions and Recommendations </heading><chunk>Salinlahi III is the third iteration in a series of systems that were developed to teach the Filipino language to heritage language learners. These learners are those who grew up oversees, but did not learn Filipino formally, but may be exposed to it through their Filipino parent(s). Based on the internal and external evaluations, Salinlahi III has a potential to be an educational software. It got a high average score on the ex- pert evaluations based on UI design, feedback, and as an educational software. The students who used the system got a positive learning gain, which means that the system was able to achieve its objective. However, since these students are residing in the Philippines, different results may arise once the system is tested on its actual target users. Salinlahi IIIs future works may include hav- ing a conversational tutor that would be able to understand other users input. This can be done by adding Natural Language Understanding techniques and tools to the current system. An- other would be to include sound into the system. Currently, the system does not support voice recognition as it is also not able to produce the tutors response through sound. Having the sys- tem support voice recognition will aid in making the tutor more conversational especially during the exercises. 92 </chunk></section><section><heading>References </heading><chunk>Brusilovsky, P., Schwarz, E., &amp;Weber, G. (1996). Elm-art: An intelligent tutoring system on world wide web. In (pp. 261269). Springer Ver- lag. Graesser, A., Lu, S., Jackson, G., Mitchell, H., Ven- tura, M., Olney, A., et al. (2004). Autotutor: A tutor with dialogue in natural language. Behav- ior Research Methods, 36, 180-192. Available from http://dx.doi.org/10.3758/BF03195563 (10.3758/BF03195563) Kassim, A. A., Kazi, S. A., &amp; Ranganath, S. (2004). A web-based intelligent learning environment for digital systems. International Journal of Engineering Education, 20, 13-23. Le, Q., &amp; Le, T. (2007) Evaluation of educational software: theory into practice. In: Technology and Teaching. Nova Science Publishers, New York, UK. ISBN 978-1-60021-699-2 Levenshtein, V. I. (1966). Binary codes capable of correcting deletions, insertions, and reversals. , 10 . Available from http://sascha.geekheim.de/wp- con- tent/uploads/2006/04/levenshtein.pdfnumber=jo urnal=Soviet Physics Doklady, publish- er=American Institute of Physics., pages=707-- 710 Massey, L. D., Psotka, J., &amp; Mutter, S. A. (1988). Intelligent tutoring systems : lessons learned / edited by joseph psotka, l. dan massey, sharon a. mutter, advisory editor, john seely brown [Book]. L. Erlbaum Associates, Hillsdale, N.J. :. Murray, T. (1999). Authoring Intelligent Tutoring Systems: An Analysis of the State of the Art. International Journal of Artificial Intelligence in Education, 10, 98-129. Nielsen, J. Heuristic Evaluation. In J. Nielsen and R.L. Mack, editors, Usability Inspection Meth- ods, John Wiley, 1994. Polson, M. C., &amp; Richardson, J. J. (Eds.). (1988). Foundations of intelligent tutoring systems. Hillsdale, NJ, USA: L. Erlbaum Associates Inc. Regalado, R. V. , Antay, M. R., Fernandez, L., Cheng, C., &amp; Jumarang, L. (2010). Building web-based Filipino language learning tool for heritage learners. Philippine Information Technology Journal, Vol. 2, Issue No. 2, pp 54- 57. Shier, R. (2004). Statistics: Paired t-tests. Retrieved from http://mlsc.lboro.ac.uk/resources/statistics/Paire dttest.pdf Schon, D. A. (1987). Educating the reflective practi- tioner (Vol. 58) (No. 4). Jossey-Bass. 93 </chunk></section></sec_map>